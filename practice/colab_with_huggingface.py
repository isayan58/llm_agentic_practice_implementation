# -*- coding: utf-8 -*-
"""Colab_with_HuggingFace.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aN4zhYnM-paVng_y6VPHuTkekcubhJPE
"""

!pip install -q --upgrade datasets==3.6.0

from transformers import pipeline
import torch
from google.colab import userdata
from diffusers import DiffusionPipeline
from datasets import load_dataset
import soundfile as sf
from IPython.display import Audio
from __future__ import annotations
from huggingface_hub import login as hf_login

def login(token, add_to_git_credential):
    """
    Log in to Hugging Face using a personal access token.

    Args:
        token: Hugging Face token string (e.g., "hf_...").
        add_to_git_credential: If True, also store the token in git credential helper.
    """
    if not token:
        raise ValueError("Hugging Face token is required.")
    if not token.startswith("hf_"):
        raise ValueError("Hugging Face token must start with 'hf_'.")
    # This will validate and persist the token in the HF cache.
    hf_login(token=token, add_to_git_credential=add_to_git_credential)

hf_token = userdata.get("HF_TOKEN")
if hf_token and hf_token.startswith("hf_"):
  print("HuggingFace key looks good so far.")
else:
  print("HuggingFace key is not set.")
login(hf_token, add_to_git_credential=True)

# my_pipeline = pipeline(task, model, device)
my_pipeline = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
result = my_pipeline("I am super excited about learning LLMs but the course is way too slow.")
print(result)

ner = pipeline("ner")
result = ner("AI Engineers would love to use Huggingface")
print(result)

question =
